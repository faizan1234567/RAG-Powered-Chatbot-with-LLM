{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77448887-ed71-48e1-bf0d-2ff499d0c7ca",
   "metadata": {},
   "source": [
    "# Lesson 1 - Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ea165",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1. \n",
    "\n",
    "To access the `requirement.txt` file, go to `File` and click on `Open`.\n",
    " \n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd7dd",
   "metadata": {},
   "source": [
    "### Import the Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809aa032-d737-450d-aafa-e32bfba9d8f8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9385d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version\n",
      "---------------------- -----------\n",
      "alembic                1.11.1\n",
      "antlr4-python3-runtime 4.9.3\n",
      "asttokens              2.2.1\n",
      "attrs                  23.1.0\n",
      "backcall               0.2.0\n",
      "blinker                1.6.2\n",
      "build                  0.10.0\n",
      "CacheControl           0.12.14\n",
      "certifi                2022.12.7\n",
      "charset-normalizer     3.1.0\n",
      "cleo                   2.0.1\n",
      "click                  8.1.6\n",
      "cloudpickle            2.2.1\n",
      "colorama               0.4.6\n",
      "comm                   0.1.3\n",
      "contourpy              1.0.7\n",
      "crashtest              0.4.1\n",
      "cycler                 0.11.0\n",
      "databricks-cli         0.17.7\n",
      "debugpy                1.6.7\n",
      "decorator              5.1.1\n",
      "Deprecated             1.2.13\n",
      "distlib                0.3.6\n",
      "docker                 6.1.3\n",
      "dulwich                0.21.5\n",
      "entrypoints            0.4\n",
      "et-xmlfile             1.1.0\n",
      "executing              1.2.0\n",
      "Farama-Notifications   0.0.4\n",
      "filelock               3.12.0\n",
      "Flask                  2.3.2\n",
      "fonttools              4.39.3\n",
      "gitdb                  4.0.10\n",
      "GitPython              3.1.32\n",
      "greenlet               2.0.2\n",
      "gymnasium              0.28.1\n",
      "html5lib               1.1\n",
      "hydra-core             1.3.2\n",
      "idna                   3.4\n",
      "imageio                2.31.0\n",
      "importlib-metadata     4.13.0\n",
      "importlib-resources    5.12.0\n",
      "installer              0.7.0\n",
      "ipykernel              6.24.0\n",
      "ipython                8.12.2\n",
      "itsdangerous           2.1.2\n",
      "jaraco.classes         3.2.3\n",
      "jax-jumpy              1.0.0\n",
      "jedi                   0.18.2\n",
      "Jinja2                 3.1.2\n",
      "joblib                 1.3.1\n",
      "jsonschema             4.17.3\n",
      "jupyter_client         8.3.0\n",
      "jupyter_core           5.3.1\n",
      "keyring                23.13.1\n",
      "kiwisolver             1.4.4\n",
      "lockfile               0.12.2\n",
      "Mako                   1.2.4\n",
      "Markdown               3.4.3\n",
      "MarkupSafe             2.1.2\n",
      "matplotlib             3.7.1\n",
      "matplotlib-inline      0.1.6\n",
      "mlflow                 2.5.0\n",
      "more-itertools         9.1.0\n",
      "mpmath                 1.3.0\n",
      "msgpack                1.0.5\n",
      "msvc-runtime           14.34.31931\n",
      "nest-asyncio           1.5.6\n",
      "networkx               3.1\n",
      "numpy                  1.24.4\n",
      "oauthlib               3.2.2\n",
      "omegaconf              2.3.0\n",
      "opencv-python          4.7.0.72\n",
      "openpyxl               3.1.2\n",
      "packaging              23.1\n",
      "pandas                 2.0.2\n",
      "parso                  0.8.3\n",
      "pexpect                4.8.0\n",
      "pickleshare            0.7.5\n",
      "Pillow                 9.5.0\n",
      "pip                    23.3.2\n",
      "pkginfo                1.9.6\n",
      "pkgutil_resolve_name   1.3.10\n",
      "platformdirs           3.5.1\n",
      "poetry                 1.5.1\n",
      "poetry-core            1.6.1\n",
      "poetry-plugin-export   1.4.0\n",
      "prompt-toolkit         3.0.39\n",
      "protobuf               4.23.4\n",
      "psutil                 5.9.5\n",
      "ptyprocess             0.7.0\n",
      "pure-eval              0.2.2\n",
      "pyarrow                12.0.1\n",
      "Pygments               2.15.1\n",
      "PyJWT                  2.8.0\n",
      "pyparsing              3.0.9\n",
      "pyproject_hooks        1.0.0\n",
      "pyrsistent             0.19.3\n",
      "python-dateutil        2.8.2\n",
      "pytz                   2023.3\n",
      "pywin32                306\n",
      "pywin32-ctypes         0.2.0\n",
      "PyYAML                 6.0.1\n",
      "pyzmq                  25.1.0\n",
      "querystring-parser     1.2.4\n",
      "rapidfuzz              2.15.1\n",
      "requests               2.29.0\n",
      "requests-toolbelt      1.0.0\n",
      "scikit-learn           1.3.0\n",
      "scipy                  1.10.1\n",
      "seaborn                0.12.2\n",
      "setuptools             65.5.0\n",
      "shellingham            1.5.0.post1\n",
      "six                    1.16.0\n",
      "smmap                  5.0.0\n",
      "SQLAlchemy             2.0.19\n",
      "sqlparse               0.4.4\n",
      "stable-baselines3      2.0.0a13\n",
      "stack-data             0.6.2\n",
      "sympy                  1.11.1\n",
      "synapseclient          2.7.1\n",
      "tabulate               0.9.0\n",
      "threadpoolctl          3.2.0\n",
      "tomli                  2.0.1\n",
      "tomlkit                0.11.8\n",
      "torch                  2.0.1\n",
      "tornado                6.3.2\n",
      "tqdm                   4.66.1\n",
      "traitlets              5.9.0\n",
      "trove-classifiers      2023.5.24\n",
      "typing_extensions      4.5.0\n",
      "tzdata                 2023.3\n",
      "urllib3                1.26.15\n",
      "virtualenv             20.23.0\n",
      "waitress               2.1.2\n",
      "wcwidth                0.2.6\n",
      "webencodings           0.5.1\n",
      "websocket-client       1.6.1\n",
      "Werkzeug               2.3.6\n",
      "wrapt                  1.15.0\n",
      "zipp                   3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30698fb9-4709-4088-9905-9ccb4efd5e09",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pinecone, ServerlessSpec\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from DLAIUtils import Utils\n",
    "import DLAIUtils\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab484bb-3bfb-4c52-a5bd-bcbe4a7a63d2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92fc2d",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce859e4b-9b50-4f53-b357-28d3e3872c87",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('quora', split='train[240000:290000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d4112-fa51-4092-9841-8b266e3b6a2c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d1241-61ae-4d09-bf46-52081c133c0c",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "questions = []\n",
    "for record in dataset['questions']:\n",
    "    questions.extend(record['text'])\n",
    "question = list(set(questions))\n",
    "print('\\n'.join(questions[:10]))\n",
    "print('-' * 50)\n",
    "print(f'Number of questions: {len(questions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c0402",
   "metadata": {},
   "source": [
    "### Check cuda and Setup the model\n",
    "\n",
    "**Note**: \"Checking cuda\" refers to checking if you have access to GPUs (faster compute). In this course, we are using CPUs. So, you might notice some code cells taking a little longer to run.\n",
    "\n",
    "We are using *all-MiniLM-L6-v2* sentence-transformers model that maps sentences to a 384 dimensional dense vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb67759-ab38-4472-bfb0-4a56d1c05955",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device != 'cuda':\n",
    "    print('Sorry no cuda.')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ec5ec-5397-4ed5-8163-7a901b6ecb0c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "query = 'which city is the most populated in the world?'\n",
    "xq = model.encode(query)\n",
    "xq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780a189",
   "metadata": {},
   "source": [
    "### Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3a94e-127f-4667-a9ae-7a17d7304ee6",
   "metadata": {
    "height": 43
   },
   "outputs": [],
   "source": [
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a75eca-60f0-478b-bdcf-b68732c1545d",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "print(INDEX_NAME)\n",
    "pinecone.create_index(name=INDEX_NAME, \n",
    "    dimension=model.get_sentence_embedding_dimension(), \n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n",
    "\n",
    "index = pinecone.Index(INDEX_NAME)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d9424",
   "metadata": {},
   "source": [
    "### Create Embeddings and Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea551303-aa81-41cd-adc5-dc9ea8072397",
   "metadata": {
    "height": 352
   },
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "vector_limit=10000\n",
    "\n",
    "questions = question[:vector_limit]\n",
    "\n",
    "import json\n",
    "\n",
    "for i in tqdm(range(0, len(questions), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(questions))\n",
    "    # create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in questions[i:i_end]]\n",
    "    # create embeddings\n",
    "    xc = model.encode(questions[i:i_end])\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, xc, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153920a-f4c4-420e-9790-262dd2299fc6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71135418",
   "metadata": {},
   "source": [
    "### Run Your Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b20b81-4782-4ce2-aec3-9576c7779f2e",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# small helper function so we can repeat queries later\n",
    "def run_query(query):\n",
    "  embedding = model.encode(query).tolist()\n",
    "  results = index.query(top_k=10, vector=embedding, include_metadata=True, include_values=False)\n",
    "  for result in results['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4244d6-7be0-4ee1-a36a-0d586f0555f7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "run_query('which city has the highest population in the world?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b20fe-2328-47eb-84cd-bf3b27c6d4aa",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "query = 'how do i make chocolate cake?'\n",
    "run_query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
